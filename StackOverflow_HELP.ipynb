{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ff1b8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (4.17.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from selenium) (2.0.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: webdriver_manager in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from webdriver_manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from webdriver_manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from webdriver_manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from requests->webdriver_manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from requests->webdriver_manager) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pablo\\anaconda3\\envs\\py39\\lib\\site-packages (from requests->webdriver_manager) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install --upgrade webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43b9b359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from time import strftime, gmtime\n",
    "\n",
    "from selenium.common.exceptions import (\n",
    "    ElementNotSelectableException, \n",
    "    ElementNotVisibleException,\n",
    "    NoSuchElementException,\n",
    "    TimeoutException, \n",
    "    WebDriverException, \n",
    "    WebDriverException\n",
    "    )\n",
    "\n",
    "import random\n",
    "\n",
    "import speech_recognition as sr\n",
    "import ffmpy\n",
    "import requests\n",
    "import urllib\n",
    "import pydub\n",
    "\n",
    "negrita = \"\\033[1m\"\n",
    "reset = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7575030d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92fc4a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abrir_google():\n",
    "    \n",
    "    search_url = \"https://www.google.com/search?q=google&oq=google&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBBzkxOWowajGoAgCwAgA&sourceid=chrome&ie=UTF-8\"\n",
    "    \n",
    "    webd.get(search_url)\n",
    "    \n",
    "    try:\n",
    "        boton_aceptar_todo=webd.find_element(By.CSS_SELECTOR,'button[id=\"L2AGLb\"]')\n",
    "        boton_aceptar_todo.click()\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b7669ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abrir_stack():\n",
    "    \n",
    "    busqueda_google = webd.find_element(By.CSS_SELECTOR, 'textarea[role=\"combobox\"]')\n",
    "    \n",
    "    for _ in range(6):\n",
    "        busqueda_google.send_keys(Keys.BACK_SPACE)\n",
    "        time.sleep(random.uniform(0,0.7))\n",
    "    \n",
    "    busqueda_google.send_keys('Stack Overflow')\n",
    "    busqueda_google.send_keys(Keys.ENTER)\n",
    "    \n",
    "    #Abrir el primer link\n",
    "    primer_link = webd.find_element(By.CSS_SELECTOR,'a[href=\"https://stackoverflow.com/\"]')\n",
    "    primer_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0497ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aceptar_cookies():\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        WebDriverWait(webd,10).until(ec.visibility_of_element_located((By.CSS_SELECTOR,'button[id=\"onetrust-accept-btn-handler\"]')))\n",
    "        boton_aceptar = webd.find_element(By.CSS_SELECTOR,'button[id=\"onetrust-accept-btn-handler\"]')\n",
    "        \n",
    "        boton_aceptar.click()\n",
    "        \n",
    "    except (NoSuchElementException, TimeoutException) as ex:\n",
    "        \n",
    "        print(\"No se han podido aceptar las cookies: \",type(ex))\n",
    "        webd.quit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd6fdd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_final(textos, num_respuestas):\n",
    "    \n",
    "    pregunta=BeautifulSoup(str(textos[0].text),'html.parser')\n",
    "    print(f\"\\n{negrita}La pregunta realizada fue:{reset}\\n{pregunta}\\n\")\n",
    "    \n",
    "    for num in range(min(int(num_respuestas),len(textos))):\n",
    "                     \n",
    "        respuesta=BeautifulSoup(str(textos[int(num+1)].text),'html.parser')\n",
    "        print(f\"{negrita}La {num+1} respuesta mejor valorada fue:{reset}\\n{str(respuesta)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2002dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SOS_help(error):\n",
    "    \n",
    "    time.sleep(random.uniform(0,3))\n",
    "    \n",
    "    boton_buscar=webd.find_element(By.CSS_SELECTOR,'input[role=\"combobox\"]')\n",
    "    boton_buscar.send_keys(str(error))\n",
    "    boton_buscar.send_keys(Keys.ENTER)\n",
    "    \n",
    "    time.sleep(random.uniform(0,3))\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        iframe = webd.find_element(By.CSS_SELECTOR, 'iframe[title=\"reCAPTCHA\"]')\n",
    "        webd.switch_to.frame(iframe)\n",
    "        boton_capcha=webd.find_element(By.XPATH,'//*[@id=\"recaptcha-anchor\"]/div[1]').click()\n",
    "        webd.switch_to.default_content()\n",
    "        print(f\"\\n{negrita}RESUELVA EL CAPTCHA MANUALMENTE{reset}\\n\")\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    WebDriverWait(webd,10000).until(ec.visibility_of_element_located((By.XPATH,'//*[@id=\"mainbar\"]/div[4]/div[2]/div/nav/button')))\n",
    "    boton_more=webd.find_element(By.XPATH,'//*[@id=\"mainbar\"]/div[4]/div[2]/div/nav/button')\n",
    "    boton_more.click()\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "    boton_score=webd.find_element(By.XPATH,'//*[@id=\"mainbar\"]/div[4]/div[2]/div/nav/ul/li[2]/a')\n",
    "    boton_score.click()\n",
    "    \n",
    "    time.sleep(random.uniform(0,3))\n",
    "    \n",
    "    solution = webd.find_elements(By.CSS_SELECTOR, \"a[data-searchsession]\")\n",
    "    solution[0].click()\n",
    "\n",
    "    time.sleep(random.uniform(1.5,2.5))\n",
    "    \n",
    "    num_respuestas=input(\"¿Cuántas respuestas quieres?: \")\n",
    "    \n",
    "    textos=webd.find_elements(By.CSS_SELECTOR, 'div[class=\"s-prose js-post-body\"]')\n",
    "    \n",
    "    print_final(textos,num_respuestas)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b665253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduce el error que quieras buscar en Stack Overflow: How can I pivot a dataframe?\n",
      "¿Cuántas respuestas quieres?: 2\n",
      "\n",
      "\u001b[1mLa pregunta realizada fue:\u001b[0m\n",
      "I have a pandas dataframe, df:\n",
      "   c1   c2\n",
      "0  10  100\n",
      "1  11  110\n",
      "2  12  120\n",
      "How do I iterate over the rows of this dataframe? For every row, I want to access its elements (values in cells) by the name of the columns. For example:\n",
      "for row in df.rows:\n",
      "    print(row['c1'], row['c2'])\n",
      "I found a similar question, which suggests using either of these:\n",
      "for date, row in df.T.iteritems():\n",
      "for row in df.iterrows():\n",
      "But I do not understand what the row object is and how I can work with it.\n",
      "\n",
      "\u001b[1mLa 1 respuesta mejor valorada fue:\u001b[0m\n",
      "DataFrame.iterrows is a generator which yields both the index and row (as a Series):\n",
      "import pandas as pd\n",
      "\n",
      "df = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})\n",
      "df = df.reset_index()  # make sure indexes pair with number of rows\n",
      "\n",
      "for index, row in df.iterrows():\n",
      "    print(row['c1'], row['c2'])\n",
      "10 100\n",
      "11 110\n",
      "12 120\n",
      "Obligatory disclaimer from the documentation\n",
      "Iterating through pandas objects is generally slow. In many cases, iterating manually over the rows is not needed and can be avoided with one of the following approaches:\n",
      "Look for a vectorized solution: many operations can be performed using built-in methods or NumPy functions, (boolean) indexing, …\n",
      "When you have a function that cannot work on the full DataFrame/Series at once, it is better to use apply() instead of iterating over the values. See the docs on function application.\n",
      "If you need to do iterative manipulations on the values but performance is important, consider writing the inner loop with cython or numba. See the enhancing performance section for some examples of this approach.\n",
      "Other answers in this thread delve into greater depth on alternatives to iter* functions if you are interested to learn more.\n",
      "\n",
      "\u001b[1mLa 2 respuesta mejor valorada fue:\u001b[0m\n",
      "How to iterate over rows in a DataFrame in Pandas\n",
      "Answer: DON'T*!\n",
      "Iteration in Pandas is an anti-pattern and is something you should only do when you have exhausted every other option. You should not use any function with \"iter\" in its name for more than a few thousand rows or you will have to get used to a lot of waiting.\n",
      "Do you want to print a DataFrame? Use DataFrame.to_string().\n",
      "Do you want to compute something? In that case, search for methods in this order (list modified from here):\n",
      "Vectorization\n",
      "Cython routines\n",
      "List Comprehensions (vanilla for loop)\n",
      "DataFrame.apply(): i)  Reductions that can be performed in Cython, ii) Iteration in Python space\n",
      "items() iteritems() (deprecated since v1.5.0)\n",
      "DataFrame.itertuples()\n",
      "DataFrame.iterrows()\n",
      "iterrows and itertuples (both receiving many votes in answers to this question) should be used in very rare circumstances, such as generating row objects/nametuples for sequential processing, which is really the only thing these functions are useful for.\n",
      "Appeal to Authority\n",
      "The documentation page on iteration has a huge red warning box that says:\n",
      "Iterating through pandas objects is generally slow. In many cases, iterating manually over the rows is not needed [...].\n",
      "* It's actually a little more complicated than \"don't\". df.iterrows() is the correct answer to this question, but \"vectorize your ops\" is the better one. I will concede that there are circumstances where iteration cannot be avoided (for example, some operations where the result depends on the value computed for the previous row). However, it takes some familiarity with the library to know when. If you're not sure whether you need an iterative solution, you probably don't. PS: To know more about my rationale for writing this answer, skip to the very bottom.\n",
      "Faster than Looping: Vectorization, Cython\n",
      "A good number of basic operations and computations are \"vectorised\" by pandas (either through NumPy, or through Cythonized functions). This includes arithmetic, comparisons, (most) reductions, reshaping (such as pivoting), joins, and groupby operations. Look through the documentation on Essential Basic Functionality to find a suitable vectorised method for your problem.\n",
      "If none exists, feel free to write your own using custom Cython extensions.\n",
      "Next Best Thing: List Comprehensions*\n",
      "List comprehensions should be your next port of call if 1) there is no vectorized solution available, 2) performance is important, but not important enough to go through the hassle of cythonizing your code, and 3) you're trying to perform elementwise transformation on your code. There is a good amount of evidence to suggest that list comprehensions are sufficiently fast (and even sometimes faster) for many common Pandas tasks.\n",
      "The formula is simple,\n",
      "# Iterating over one column - `f` is some function that processes your data\n",
      "result = [f(x) for x in df['col']]\n",
      "\n",
      "# Iterating over two columns, use `zip`\n",
      "result = [f(x, y) for x, y in zip(df['col1'], df['col2'])]\n",
      "\n",
      "# Iterating over multiple columns - same data type\n",
      "result = [f(row[0], ..., row[n]) for row in df[['col1', ...,'coln']].to_numpy()]\n",
      "\n",
      "# Iterating over multiple columns - differing data type\n",
      "result = [f(row[0], ..., row[n]) for row in zip(df['col1'], ..., df['coln'])]\n",
      "If you can encapsulate your business logic into a function, you can use a list comprehension that calls it. You can make arbitrarily complex things work through the simplicity and speed of raw Python code.\n",
      "Caveats\n",
      "List comprehensions assume that your data is easy to work with - what that means is your data types are consistent and you don't have NaNs, but this cannot always be guaranteed.\n",
      "The first one is more obvious, but when dealing with NaNs, prefer in-built pandas methods if they exist (because they have much better corner-case handling logic), or ensure your business logic includes appropriate NaN handling logic.\n",
      "When dealing with mixed data types you should iterate over zip(df['A'], df['B'], ...) instead of df[['A', 'B']].to_numpy() as the latter implicitly upcasts data to the most common type. As an example if A is numeric and B is string, to_numpy() will cast the entire array to string, which may not be what you want. Fortunately zipping your columns together is the most straightforward workaround to this.\n",
      "*Your mileage may vary for the reasons outlined in the Caveats section above.\n",
      "An Obvious Example\n",
      "Let's demonstrate the difference with a simple example of adding two pandas columns A + B. This is a vectorizable operation, so it will be easy to contrast the performance of the methods discussed above.\n",
      "Benchmarking code, for your reference. The line at the bottom measures a function written in numpandas, a style of Pandas that mixes heavily with NumPy to squeeze out maximum performance. Writing numpandas code should be avoided unless you know what you're doing. Stick to the API where you can (i.e., prefer vec over vec_numpy).\n",
      "I should mention, however, that it isn't always this cut and dry. Sometimes the answer to \"what is the best method for an operation\" is \"it depends on your data\". My advice is to test out different approaches on your data before settling on one.\n",
      "My Personal Opinion *\n",
      "Most of the analyses performed on the various alternatives to the iter family has been through the lens of performance. However, in most situations you will typically be working on a reasonably sized dataset (nothing beyond a few thousand or 100K rows) and performance will come second to simplicity/readability of the solution.\n",
      "Here is my personal preference when selecting a method to use for a problem.\n",
      "For the novice:\n",
      "Vectorization (when possible); apply(); List Comprehensions; itertuples()/iteritems(); iterrows(); Cython\n",
      "For the more experienced:\n",
      "Vectorization (when possible); apply(); List Comprehensions; Cython; itertuples()/iteritems(); iterrows()\n",
      "Vectorization prevails as the most idiomatic method for any problem that can be vectorized. Always seek to vectorize! When in doubt, consult the docs, or look on Stack Overflow for an existing question on your particular task.\n",
      "I do tend to go on about how bad apply is in a lot of my posts, but I do concede it is easier for a beginner to wrap their head around what it's doing. Additionally, there are quite a few use cases for apply has explained in this post of mine.\n",
      "Cython ranks lower down on the list because it takes more time and effort to pull off correctly. You will usually never need to write code with pandas that demands this level of performance that even a list comprehension cannot satisfy.\n",
      "* As with any personal opinion, please take with heaps of salt!\n",
      "Further Reading\n",
      "10 Minutes to pandas, and Essential Basic Functionality - Useful links that introduce you to Pandas and its library of vectorized*/cythonized functions.\n",
      "Enhancing Performance - A primer from the documentation on enhancing standard Pandas operations\n",
      "Are for-loops in pandas really bad? When should I care? - a detailed write-up by me on list comprehensions and their suitability for various operations (mainly ones involving non-numeric data)\n",
      "When should I (not) want to use pandas apply() in my code? - apply is slow (but not as slow as the iter* family. There are, however, situations where one can (or should) consider apply as a serious alternative, especially in some GroupBy operations).\n",
      "* Pandas string methods are \"vectorized\" in the sense that they are specified on the series but operate on each element. The underlying mechanisms are still iterative, because string operations are inherently hard to vectorize.\n",
      "Why I Wrote this Answer\n",
      "A common trend I notice from new users is to ask questions of the form \"How can I iterate over my df to do X?\". Showing code that calls iterrows() while doing something inside a for loop. Here is why. A new user to the library who has not been introduced to the concept of vectorization will likely envision the code that solves their problem as iterating over their data to do something. Not knowing how to iterate over a DataFrame, the first thing they do is Google it and end up here, at this question. They then see the accepted answer telling them how to, and they close their eyes and run this code without ever first questioning if iteration is the right thing to do.\n",
      "The aim of this answer is to help new users understand that iteration is not necessarily the solution to every problem, and that better, faster and more idiomatic solutions could exist, and that it is worth investing time in exploring them. I'm not trying to start a war of iteration vs. vectorization, but I want new users to be informed when developing solutions to their problems with this library.\n",
      "And finally ... a TLDR to summarize this post\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service = Service(executable_path=r'C:\\Users\\pablo\\Desktop\\chromedriver-win32\\chromedriver-win32\\chromedriver.exe')\n",
    "options = webdriver.ChromeOptions()\n",
    "webd = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "abrir_google()\n",
    "abrir_stack()\n",
    "aceptar_cookies()\n",
    "\n",
    "error=input(\"Introduce el error que quieras buscar en Stack Overflow: \")\n",
    "#error que busco: Can't install time module\n",
    "get_SOS_help(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1edcee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d335c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
